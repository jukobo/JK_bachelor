{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from AE_functions import *\n",
    "from make_dataset import *\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First try, simple NN\n",
    "\n",
    "Training on one image with Adam optimizer (lr = 1e-5) and AdamW optimizer (lr = 1e-3)\n",
    "\n",
    "Training on one image with AdamW optimizer and varying architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=12288, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=1024, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=1024, out_features=12288, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.20025663077831268\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.001954636536538601\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.00020431286247912794\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 1.7554895748617128e-05\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 2.086589347527479e-06\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 1.1441942859846677e-07\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 8.120175643000493e-09\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 5.237492106680008e-10\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 7.107791438754063e-11\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 5.600085065810001e-12\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 2.2809786828434375e-13\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 1.4867610181185098e-14\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 1.2399857616390841e-14\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 7.290442223170917e-15\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 2.953680120040998e-14\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 1.4815053480873863e-14\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 5.9857988791295336e-15\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 1.1284229674529255e-14\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 2.2537061531769688e-14\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 4.850078892242602e-15\n"
     ]
    }
   ],
   "source": [
    "#Define paramters\n",
    "parameters_dict = {\n",
    "    'epochs': 500,\n",
    "    'learning_rate': 1e-3, #NOTE - change here\n",
    "    'batch_size': 1, \n",
    "    'weight_decay': 5e-4 \n",
    "}\n",
    "\n",
    "## Unpack parameters\n",
    "num_epochs = parameters_dict['epochs']\n",
    "lr = parameters_dict['learning_rate']\n",
    "batch_size = parameters_dict['batch_size']\n",
    "wd = parameters_dict['weight_decay']\n",
    "\n",
    "\n",
    "## Loading data\n",
    "\n",
    "img_dir_training = \"C:/Users/julie/Bachelor_data/crops_training_prep/img\"\n",
    "heatmap_dir_training = \"C:/Users/julie/Bachelor_data/crops_training_prep/heatmaps\"\n",
    "msk_dir_training = \"C:/Users/julie/Bachelor_data/crops_training_prep/msk\"\n",
    "\n",
    "\n",
    "VerSe_train = LoadData(img_dir=img_dir_training, msk_dir = msk_dir_training, distfield_dir=heatmap_dir_training)\n",
    "train_loader = DataLoader(VerSe_train, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    # 39 elements (images) in train_loader\n",
    "    # Each element is a tuple of 3 elements: (img, heatmap, msk)\n",
    "    # img: torch.Size([2, 128, 128, 96])\n",
    "\n",
    "input_train, y, z = train_loader.dataset[10]\n",
    "# plt.imshow(input_train[0][64, :, :], cmap='gray')\n",
    "# plt.title('Original')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "## Define model\n",
    "# For simple AE\n",
    "# model = AE([128*96, 512, 256, 128])\n",
    "# model = AE([128*96, 512, 256, 128, 64])\n",
    "model = AE([128*96, 2*512, 2*256, 2*128, 2*64])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "\n",
    "o_loss = []\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "recon_img = []\n",
    "recon_img.append(input_train[0][64,:,:].numpy())\n",
    "recon_img_name = []\n",
    "recon_img_name.append('Original')\n",
    "\n",
    "## Train model\n",
    "def train(model, optimizer, epochs, device):\n",
    "    model.train()\n",
    "    step = -1\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        overall_loss = 0\n",
    "\n",
    "        x = input_train[0][64,:,:].unsqueeze(dim=0)\n",
    "        x = x.view(1, -1)\n",
    "        x = x.to(device)\n",
    "\n",
    "        x_reconstructed = model(x)\n",
    "\n",
    "        #-- Loss function\n",
    "        loss = loss_function(x_reconstructed, x)\n",
    "\n",
    "        overall_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update step\n",
    "        step+=1\n",
    "\n",
    "        # Do evaluation every 50 epoch\n",
    "        if step%25 == 0:\n",
    "            print()\n",
    "            print(\"EVALUATION!\")\n",
    "            model.eval() #Set to evaluation\n",
    "\n",
    "            #Training evaluation\n",
    "            val_loss_eval = []\n",
    "            with torch.no_grad():\n",
    "                inputs = input_train[0][64,:,:].unsqueeze(dim=0)\n",
    "                inputs = inputs.view(1, -1)\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                inputs_reconstructed = model(inputs)\n",
    "                \n",
    "                #-- Loss function\n",
    "                v_loss = loss_function(inputs_reconstructed, inputs)\n",
    "\n",
    "                #-- Save image\n",
    "                if step%50 == 0:\n",
    "                    recon_img.append(inputs_reconstructed.detach().cpu().numpy().reshape(128, 96))\n",
    "                    recon_img_name.append('Reconstructed image, '+str(step)+' epochs')\n",
    "\n",
    "\n",
    "                # Save loss\n",
    "                val_loss_eval.append(v_loss.item())\n",
    "            avg_loss_val = np.mean(val_loss_eval)\n",
    "            print(\"Validation loss: \"+str(avg_loss_val))\n",
    "            val_loss.append(avg_loss_val)\n",
    "\n",
    "\n",
    "        o_loss.append(overall_loss)  \n",
    "    \n",
    "\n",
    "train(model, optimizer, num_epochs, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged towards 1.1500661816558234e-14\n"
     ]
    }
   ],
   "source": [
    "## Plotting losses from training\n",
    "\n",
    "print(f\"Converged towards {np.mean(o_loss[350:])}\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(f'Model Loss, batch_size=1, lr={lr}, wd=0.0005')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Avg. loss')\n",
    "ax.set_xticks(np.arange(0, len(o_loss), step= 25))\n",
    "\n",
    "ax.plot(list(range(1, len(o_loss)+1, 1)), o_loss, label='Training loss', color='b')  # Update the plot with the current loss\n",
    "ax.plot(list(range(25, len(o_loss)+1, 25)), val_loss, label='Validation loss', color='r')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting reconstructed images\n",
    "\n",
    "fig, ax  = plt.subplots(2, 3, figsize=(12, 15))\n",
    "ii = [0, 1, 2, 3, 6, 10]\n",
    "\n",
    "for i in range(1,6):\n",
    "    ax[i//3, i%3].imshow(recon_img[ii[i]], cmap='gray')\n",
    "    ax[i//3, i%3].set_title(recon_img_name[ii[i]])\n",
    "\n",
    "\n",
    "ax[0,0].imshow(input_train[0][64, :, :], cmap='gray')\n",
    "ax[0,0].set_title('Original Image')\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=4.601564423012579e-14\n",
      "tensor(-5.9605e-07) tensor(4.0978e-07)\n"
     ]
    }
   ],
   "source": [
    "## DONT USE - Make reconstruction\n",
    "\n",
    "model.eval()\n",
    "input_train, y, z = train_loader.dataset[10]\n",
    "org_img = input_train[0][64,:,:].unsqueeze(dim=0)\n",
    "x = org_img.view(1, -1)\n",
    "\n",
    "x = x.to(device)\n",
    "x_reconstructed = model(x) \n",
    "print(f'loss={loss_function(x_reconstructed, x)}')\n",
    "\n",
    "x_reconstructed = x_reconstructed.detach().cpu().numpy().reshape(128, 96)\n",
    "\n",
    "diff_img = org_img.squeeze() - x_reconstructed\n",
    "print(torch.min(diff_img), torch.max(diff_img))\n",
    "\n",
    "\n",
    "## Plotting the difference from outlier input to reconstructions\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "ax[0].imshow(org_img.squeeze(), cmap='gray')\n",
    "ax[0].set_title('Original Image')\n",
    "\n",
    "ax[1].imshow(x_reconstructed, cmap='gray')\n",
    "ax[1].set_title('Reconstructed Image')\n",
    "\n",
    "diff_plot = ax[2].imshow(diff_img, vmin=-0.3, vmax=0.3, cmap='bwr')\n",
    "ax[2].set_title('Difference')\n",
    "fig.colorbar(diff_plot, ax=ax[2])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second try, Convolutional NN UNet, part 1\n",
    "\n",
    "Training with one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_AE_UNet(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): ConvTranspose2d(8, 8, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (8): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(8, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): ConvTranspose2d(4, 4, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (13): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (14): ReLU(inplace=True)\n",
      "    (15): Conv2d(4, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.140187606215477\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.06263485550880432\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.04729649797081947\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.04707719758152962\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.04680652916431427\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.039813727140426636\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.027934229001402855\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.0213009063154459\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.01939392276108265\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.01734662801027298\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.016115330159664154\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.014868336729705334\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.014188967645168304\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.013545013964176178\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.012661639600992203\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.010750357992947102\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.00927467830479145\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.008577332831919193\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.007872176356613636\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.007545353379100561\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.006697443779557943\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.006244406569749117\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.0058220685459673405\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.005709137301892042\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.005104540381580591\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.0052620600908994675\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.004778316244482994\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.004379098769277334\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.004427991807460785\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.00404313812032342\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.0038729317020624876\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.0038643747102469206\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.0035710225347429514\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.0034814553800970316\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.003355218330398202\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.003686777548864484\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.0031493043061345816\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.0020038315560668707\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.0016044130316004157\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.0016969343414530158\n"
     ]
    }
   ],
   "source": [
    "#Define paramters\n",
    "parameters_dict = {\n",
    "    'epochs': 1000,\n",
    "    'learning_rate': 1e-3, #NOTE - change here\n",
    "    'batch_size': 1, \n",
    "    'weight_decay': 5e-4 \n",
    "}\n",
    "\n",
    "## Unpack parameters\n",
    "num_epochs = parameters_dict['epochs']\n",
    "lr = parameters_dict['learning_rate']\n",
    "batch_size = parameters_dict['batch_size']\n",
    "wd = parameters_dict['weight_decay']\n",
    "\n",
    "\n",
    "## Loading data\n",
    "\n",
    "img_dir_training = \"C:/Users/julie/Bachelor_data/crops_training_prep/img\"\n",
    "heatmap_dir_training = \"C:/Users/julie/Bachelor_data/crops_training_prep/heatmaps\"\n",
    "msk_dir_training = \"C:/Users/julie/Bachelor_data/crops_training_prep/msk\"\n",
    "\n",
    "\n",
    "VerSe_train = LoadData(img_dir=img_dir_training, msk_dir = msk_dir_training, distfield_dir=heatmap_dir_training)\n",
    "train_loader = DataLoader(VerSe_train, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    # 39 elements (images) in train_loader\n",
    "    # Each element is a tuple of 3 elements: (img, heatmap, msk)\n",
    "    # img: torch.Size([2, 128, 128, 96])\n",
    "\n",
    "input_train, y, z = train_loader.dataset[10]\n",
    "# plt.imshow(input_train[0][64, :, :], cmap='gray')\n",
    "# plt.title('Original')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "## Define model\n",
    "# For simple AE\n",
    "model = conv_AE_UNet([1, 4, 8, 16, 32])\n",
    "# model = conv_AE_UNet([1, 8, 16, 32, 64])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "\n",
    "o_loss = []\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "recon_img = []\n",
    "recon_img.append(input_train[0][64,:,:].numpy())\n",
    "recon_img_name = []\n",
    "recon_img_name.append('Original')\n",
    "\n",
    "## Train model\n",
    "def train(model, optimizer, epochs, device):\n",
    "    model.train()\n",
    "    step = -1\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        overall_loss = 0\n",
    "\n",
    "        x = input_train[0][64,:,:].unsqueeze(dim=0)\n",
    "        x = x.to(device)\n",
    "\n",
    "        x_reconstructed = model(x)\n",
    "\n",
    "        #-- Loss function\n",
    "        loss = loss_function(x_reconstructed, x)\n",
    "\n",
    "        overall_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update step\n",
    "        step+=1\n",
    "\n",
    "        # Do evaluation every 50 epoch\n",
    "        if step%25 == 0:\n",
    "            print()\n",
    "            print(\"EVALUATION!\")\n",
    "            model.eval() #Set to evaluation\n",
    "\n",
    "            #Training evaluation\n",
    "            val_loss_eval = []\n",
    "            with torch.no_grad():\n",
    "                inputs = input_train[0][64,:,:].unsqueeze(dim=0)\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                inputs_reconstructed = model(inputs)\n",
    "                \n",
    "                #-- Loss function\n",
    "                v_loss = loss_function(inputs_reconstructed, inputs)\n",
    "\n",
    "                #-- Save image\n",
    "                if step%50 == 0:\n",
    "                    recon_img.append(inputs_reconstructed.detach().cpu().numpy().reshape(128, 96))\n",
    "                    recon_img_name.append('Reconstructed image, '+str(step)+' epochs')\n",
    "\n",
    "\n",
    "                # Save loss\n",
    "                val_loss_eval.append(v_loss.item())\n",
    "            avg_loss_val = np.mean(val_loss_eval)\n",
    "            print(\"Validation loss: \"+str(avg_loss_val))\n",
    "            val_loss.append(avg_loss_val)\n",
    "\n",
    "\n",
    "        o_loss.append(overall_loss)  \n",
    "    \n",
    "\n",
    "train(model, optimizer, num_epochs, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged towards 0.005249172089299044\n"
     ]
    }
   ],
   "source": [
    "## Plotting losses from training\n",
    "\n",
    "print(f\"Converged towards {np.mean(o_loss[350:])}\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(f'Model Loss, batch_size=1, lr={lr}, wd=0.0005')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Avg. loss')\n",
    "ax.set_xticks(np.arange(0, len(o_loss), step= 25))\n",
    "\n",
    "ax.plot(list(range(1, len(o_loss)+1, 1)), o_loss, label='Training loss', color='b')  # Update the plot with the current loss\n",
    "ax.plot(list(range(25, len(o_loss)+1, 25)), val_loss, label='Validation loss', color='r')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting reconstructed images\n",
    "\n",
    "fig, ax  = plt.subplots(2, 3, figsize=(12, 15))\n",
    "# ii = [0, 1, 2, 3, 6, 10]\n",
    "ii = [0, 1, 3, 6, 11, 20]\n",
    "\n",
    "for i in range(1,6):\n",
    "    ax[i//3, i%3].imshow(recon_img[ii[i]], cmap='gray')\n",
    "    ax[i//3, i%3].set_title(recon_img_name[ii[i]])\n",
    "\n",
    "\n",
    "ax[0,0].imshow(input_train[0][64, :, :], cmap='gray')\n",
    "ax[0,0].set_title('Original Image')\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second try, Convolutional NN, part 2\n",
    "\n",
    "Training with several images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_AE_UNet(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): ConvTranspose2d(8, 8, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (13): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (14): ReLU(inplace=True)\n",
      "    (15): Conv2d(8, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "EVALUATION, EPOCH 0!\n",
      "Validation loss: 0.3311912715435028\n",
      "\n",
      "EVALUATION, EPOCH 25!\n",
      "Validation loss: 0.0019043892389163375\n",
      "\n",
      "EVALUATION, EPOCH 50!\n",
      "Validation loss: 0.0008285275544039905\n",
      "\n",
      "EVALUATION, EPOCH 75!\n",
      "Validation loss: 0.0015832831850275397\n",
      "\n",
      "EVALUATION, EPOCH 100!\n",
      "Validation loss: 0.0009181192726828158\n",
      "\n",
      "EVALUATION, EPOCH 125!\n",
      "Validation loss: 0.0006717126816511154\n",
      "\n",
      "EVALUATION, EPOCH 150!\n",
      "Validation loss: 0.0032031750306487083\n",
      "\n",
      "EVALUATION, EPOCH 175!\n",
      "Validation loss: 0.0007945999386720359\n",
      "\n",
      "EVALUATION, EPOCH 200!\n",
      "Validation loss: 0.0007963193929754198\n",
      "\n",
      "EVALUATION, EPOCH 225!\n",
      "Validation loss: 0.0007877242751419544\n",
      "\n",
      "EVALUATION, EPOCH 250!\n",
      "Validation loss: 0.0004352349787950516\n",
      "\n",
      "EVALUATION, EPOCH 275!\n",
      "Validation loss: 0.0008521068375557661\n",
      "\n",
      "EVALUATION, EPOCH 300!\n",
      "Validation loss: 0.00064441206632182\n",
      "\n",
      "EVALUATION, EPOCH 325!\n",
      "Validation loss: 0.00034576651523821056\n",
      "\n",
      "EVALUATION, EPOCH 350!\n",
      "Validation loss: 0.0006047281785868108\n",
      "\n",
      "EVALUATION, EPOCH 375!\n",
      "Validation loss: 0.0005886193830519915\n",
      "\n",
      "EVALUATION, EPOCH 400!\n",
      "Validation loss: 0.0006423388258554041\n",
      "\n",
      "EVALUATION, EPOCH 425!\n",
      "Validation loss: 0.0007114004692994058\n",
      "\n",
      "EVALUATION, EPOCH 450!\n",
      "Validation loss: 0.0006451319786719978\n",
      "\n",
      "EVALUATION, EPOCH 475!\n",
      "Validation loss: 0.00034245019196532667\n"
     ]
    }
   ],
   "source": [
    "#Define paramters\n",
    "parameters_dict = {\n",
    "    'epochs': 500,\n",
    "    'learning_rate': 1e-3, #NOTE - change here\n",
    "    'batch_size': 1, \n",
    "    'weight_decay': 5e-4 \n",
    "}\n",
    "\n",
    "## Unpack parameters\n",
    "num_epochs = parameters_dict['epochs']\n",
    "lr = parameters_dict['learning_rate']\n",
    "batch_size = parameters_dict['batch_size']\n",
    "wd = parameters_dict['weight_decay']\n",
    "\n",
    "\n",
    "## Loading data\n",
    "\n",
    "img_dir_training = \"C:/Users/julie/Bachelor_data/crops_training_prep/img\"\n",
    "heatmap_dir_training = \"C:/Users/julie/Bachelor_data/crops_training_prep/heatmaps\"\n",
    "msk_dir_training = \"C:/Users/julie/Bachelor_data/crops_training_prep/msk\"\n",
    "\n",
    "\n",
    "VerSe_train = LoadData(img_dir=img_dir_training, msk_dir = msk_dir_training, distfield_dir=heatmap_dir_training)\n",
    "train_loader = DataLoader(VerSe_train, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    # 39 elements (images) in train_loader\n",
    "    # Each element is a tuple of 3 elements: (img, heatmap, msk)\n",
    "    # img: torch.Size([2, 128, 128, 96])\n",
    "\n",
    "input_train, y, z = train_loader.dataset[10]\n",
    "# plt.imshow(input_train[0][64, :, :], cmap='gray')\n",
    "# plt.title('Original')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "n = 100\n",
    "dataset = generate_dataset_training(train_loader, n)\n",
    "\n",
    "## Define model\n",
    "# For simple AE\n",
    "model = conv_AE_UNet([1, 8, 16, 32, 64])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "\n",
    "o_loss = []\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "recon_img = []\n",
    "recon_img.append(dataset[5].numpy())\n",
    "recon_img_name = []\n",
    "recon_img_name.append('Original')\n",
    "\n",
    "\n",
    "## Train model\n",
    "def train(model, optimizer, epochs, device):\n",
    "    model.train()\n",
    "    step = -1\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        overall_loss = 0\n",
    "\n",
    "\n",
    "        for idx, data in enumerate(dataset):\n",
    "            x = data.to(device)\n",
    "            x_reconstructed = model(x)\n",
    "\n",
    "            #-- Loss function\n",
    "            loss = loss_function(x_reconstructed, x)\n",
    "\n",
    "            overall_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update step\n",
    "            step+=1\n",
    "\n",
    "            # Do evaluation every 50 epoch\n",
    "            if step%2500 == 0: #step%750 == 0:\n",
    "                print()\n",
    "                print(f\"EVALUATION, EPOCH {epoch}!\")\n",
    "                model.eval() #Set to evaluation\n",
    "\n",
    "                #Training evaluation\n",
    "                val_loss_eval = []\n",
    "                with torch.no_grad():\n",
    "                    inputs = dataset[5]\n",
    "\n",
    "                    inputs = inputs.to(device)\n",
    "                    inputs_reconstructed = model(inputs)\n",
    "                    \n",
    "                    #-- Loss function\n",
    "                    v_loss = loss_function(inputs_reconstructed, inputs)\n",
    "\n",
    "                    #-- Save image\n",
    "                    if step%5000 == 0: #step%500 == 0: #\n",
    "                        recon_img.append(inputs_reconstructed.detach().cpu().numpy().squeeze())\n",
    "                        recon_img_name.append('Reconstructed image, '+str(epoch)+' epochs')\n",
    "\n",
    "\n",
    "                    # Save loss\n",
    "                    val_loss_eval.append(v_loss.item())\n",
    "                avg_loss_val = np.mean(val_loss_eval)\n",
    "                print(\"Validation loss: \"+str(avg_loss_val))\n",
    "                val_loss.append(avg_loss_val)\n",
    "\n",
    "\n",
    "        o_loss.append(overall_loss)  \n",
    "    \n",
    "\n",
    "train(model, optimizer, num_epochs, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged towards 0.035269860014086586\n"
     ]
    }
   ],
   "source": [
    "## Plotting losses from training\n",
    "print(f\"Converged towards {np.mean(o_loss[350:])}\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(f'Model Loss, batch_size=1, lr={lr}, wd=0.0005')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Avg. loss')\n",
    "ax.set_xticks(np.arange(0, len(o_loss), step= 100))\n",
    "\n",
    "ax.plot(list(range(1, len(o_loss)+1, 1)), o_loss, label='Training loss', color='b')  # Update the plot with the current loss\n",
    "ax.plot(list(range(25, len(o_loss)+1, 25)), val_loss, label='Validation loss', color='r')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting reconstructed images\n",
    "\n",
    "fig, ax  = plt.subplots(2, 3, figsize=(12, 15))\n",
    "ii = [0, 1, 2, 3, 6, 10]\n",
    "# ii = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "for i in range(1,6):\n",
    "    ax[i//3, i%3].imshow(recon_img[ii[i]], cmap='gray')\n",
    "    ax[i//3, i%3].set_title(recon_img_name[ii[i]])\n",
    "\n",
    "\n",
    "ax[0,0].imshow(recon_img[ii[0]][0], cmap='gray')\n",
    "ax[0,0].set_title('Original Image')\n",
    "\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
