{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from AE_functions import *\n",
    "from make_dataset import *\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First try, simple NN\n",
    "\n",
    "Training on one image with Adam optimizer (lr = 1e-5) and AdamW optimizer (lr = 1e-3)\n",
    "\n",
    "Training on one image with AdamW optimizer and varying architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=12288, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=1024, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=1024, out_features=12288, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.20025663077831268\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.001954636536538601\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 0.00020431286247912794\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 1.7554895748617128e-05\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 2.086589347527479e-06\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 1.1441942859846677e-07\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 8.120175643000493e-09\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 5.237492106680008e-10\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 7.107791438754063e-11\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 5.600085065810001e-12\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 2.2809786828434375e-13\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 1.4867610181185098e-14\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 1.2399857616390841e-14\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 7.290442223170917e-15\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 2.953680120040998e-14\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 1.4815053480873863e-14\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 5.9857988791295336e-15\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 1.1284229674529255e-14\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 2.2537061531769688e-14\n",
      "\n",
      "EVALUATION!\n",
      "Validation loss: 4.850078892242602e-15\n"
     ]
    }
   ],
   "source": [
    "#Define paramters\n",
    "parameters_dict = {\n",
    "    'epochs': 500,\n",
    "    'learning_rate': 1e-3, #NOTE - change here\n",
    "    'batch_size': 1, \n",
    "    'weight_decay': 5e-4 \n",
    "}\n",
    "\n",
    "## Unpack parameters\n",
    "num_epochs = parameters_dict['epochs']\n",
    "lr = parameters_dict['learning_rate']\n",
    "batch_size = parameters_dict['batch_size']\n",
    "wd = parameters_dict['weight_decay']\n",
    "\n",
    "\n",
    "## Loading data\n",
    "\n",
    "img_dir_training = \"C:/Users/julie/Bachelor_data/crops_training_prep/img\"\n",
    "heatmap_dir_training = \"C:/Users/julie/Bachelor_data/crops_training_prep/heatmaps\"\n",
    "msk_dir_training = \"C:/Users/julie/Bachelor_data/crops_training_prep/msk\"\n",
    "\n",
    "\n",
    "VerSe_train = LoadData(img_dir=img_dir_training, msk_dir = msk_dir_training, distfield_dir=heatmap_dir_training)\n",
    "train_loader = DataLoader(VerSe_train, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    # 39 elements (images) in train_loader\n",
    "    # Each element is a tuple of 3 elements: (img, heatmap, msk)\n",
    "    # img: torch.Size([2, 128, 128, 96])\n",
    "\n",
    "input_train, y, z = train_loader.dataset[10]\n",
    "# plt.imshow(input_train[0][64, :, :], cmap='gray')\n",
    "# plt.title('Original')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "## Define model\n",
    "# For simple AE\n",
    "# model = AE([128*96, 512, 256, 128])\n",
    "# model = AE([128*96, 512, 256, 128, 64])\n",
    "model = AE([128*96, 2*512, 2*256, 2*128, 2*64])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "\n",
    "o_loss = []\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "recon_img = []\n",
    "recon_img.append(input_train[0][64,:,:].numpy())\n",
    "recon_img_name = []\n",
    "recon_img_name.append('Original')\n",
    "\n",
    "## Train model\n",
    "def train(model, optimizer, epochs, device):\n",
    "    model.train()\n",
    "    step = -1\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        overall_loss = 0\n",
    "\n",
    "        x = input_train[0][64,:,:].unsqueeze(dim=0)\n",
    "        x = x.view(1, -1)\n",
    "        x = x.to(device)\n",
    "\n",
    "        x_reconstructed = model(x)\n",
    "\n",
    "        #-- Loss function\n",
    "        loss = loss_function(x_reconstructed, x)\n",
    "\n",
    "        overall_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss. backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update step\n",
    "        step+=1\n",
    "\n",
    "        # Do evaluation every 50 epoch\n",
    "        if step%25 == 0:\n",
    "            print()\n",
    "            print(\"EVALUATION!\")\n",
    "            model.eval() #Set to evaluation\n",
    "\n",
    "            #Training evaluation\n",
    "            val_loss_eval = []\n",
    "            with torch.no_grad():\n",
    "                inputs = input_train[0][64,:,:].unsqueeze(dim=0)\n",
    "                inputs = inputs.view(1, -1)\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                inputs_reconstructed = model(inputs)\n",
    "                \n",
    "                #-- Loss function\n",
    "                v_loss = loss_function(inputs_reconstructed, inputs)\n",
    "\n",
    "                #-- Save image\n",
    "                if step%50 == 0:\n",
    "                    recon_img.append(inputs_reconstructed.detach().cpu().numpy().reshape(128, 96))\n",
    "                    recon_img_name.append('Reconstructed image, '+str(step)+' epochs')\n",
    "\n",
    "\n",
    "                # Save loss\n",
    "                val_loss_eval.append(v_loss.item())\n",
    "            avg_loss_val = np.mean(val_loss_eval)\n",
    "            print(\"Validation loss: \"+str(avg_loss_val))\n",
    "            val_loss.append(avg_loss_val)\n",
    "\n",
    "\n",
    "        o_loss.append(overall_loss)  \n",
    "    \n",
    "\n",
    "train(model, optimizer, num_epochs, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged towards 1.1500661816558234e-14\n"
     ]
    }
   ],
   "source": [
    "## Plotting losses from training\n",
    "\n",
    "print(f\"Converged towards {np.mean(o_loss[350:])}\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(f'Model Loss, batch_size=1, lr={lr}, wd=0.0005')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Avg. loss')\n",
    "ax.set_xticks(np.arange(0, len(o_loss), step= 25))\n",
    "\n",
    "ax.plot(list(range(1, len(o_loss)+1, 1)), o_loss, label='Training loss', color='b')  # Update the plot with the current loss\n",
    "ax.plot(list(range(25, len(o_loss)+1, 25)), val_loss, label='Validation loss', color='r')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting reconstructed images\n",
    "\n",
    "fig, ax  = plt.subplots(2, 3, figsize=(12, 15))\n",
    "ii = [0, 1, 2, 3, 6, 10]\n",
    "\n",
    "for i in range(1,6):\n",
    "    ax[i//3, i%3].imshow(recon_img[ii[i]], cmap='gray')\n",
    "    ax[i//3, i%3].set_title(recon_img_name[ii[i]])\n",
    "\n",
    "\n",
    "ax[0,0].imshow(input_train[0][64, :, :], cmap='gray')\n",
    "ax[0,0].set_title('Original Image')\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=4.601564423012579e-14\n",
      "tensor(-5.9605e-07) tensor(4.0978e-07)\n"
     ]
    }
   ],
   "source": [
    "## DONT USE - Make reconstruction\n",
    "\n",
    "model.eval()\n",
    "input_train, y, z = train_loader.dataset[10]\n",
    "org_img = input_train[0][64,:,:].unsqueeze(dim=0)\n",
    "x = org_img.view(1, -1)\n",
    "\n",
    "x = x.to(device)\n",
    "x_reconstructed = model(x) \n",
    "print(f'loss={loss_function(x_reconstructed, x)}')\n",
    "\n",
    "x_reconstructed = x_reconstructed.detach().cpu().numpy().reshape(128, 96)\n",
    "\n",
    "diff_img = org_img.squeeze() - x_reconstructed\n",
    "print(torch.min(diff_img), torch.max(diff_img))\n",
    "\n",
    "\n",
    "## Plotting the difference from outlier input to reconstructions\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "ax[0].imshow(org_img.squeeze(), cmap='gray')\n",
    "ax[0].set_title('Original Image')\n",
    "\n",
    "ax[1].imshow(x_reconstructed, cmap='gray')\n",
    "ax[1].set_title('Reconstructed Image')\n",
    "\n",
    "diff_plot = ax[2].imshow(diff_img, vmin=-0.3, vmax=0.3, cmap='bwr')\n",
    "ax[2].set_title('Difference')\n",
    "fig.colorbar(diff_plot, ax=ax[2])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second try, Convolutional NN, part 1\n",
    "\n",
    "Training with one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define paramters\n",
    "parameters_dict = {\n",
    "    'epochs': 500,\n",
    "    'learning_rate': 1e-3, #NOTE - change here\n",
    "    'batch_size': 1, \n",
    "    'weight_decay': 5e-4 \n",
    "}\n",
    "\n",
    "## Unpack parameters\n",
    "num_epochs = parameters_dict['epochs']\n",
    "lr = parameters_dict['learning_rate']\n",
    "batch_size = parameters_dict['batch_size']\n",
    "wd = parameters_dict['weight_decay']\n",
    "\n",
    "\n",
    "## Loading data\n",
    "\n",
    "img_dir_training = \"C:/Users/julie/Bachelor_data/crops_training_prep/img\"\n",
    "heatmap_dir_training = \"C:/Users/julie/Bachelor_data/crops_training_prep/heatmaps\"\n",
    "msk_dir_training = \"C:/Users/julie/Bachelor_data/crops_training_prep/msk\"\n",
    "\n",
    "\n",
    "VerSe_train = LoadData(img_dir=img_dir_training, msk_dir = msk_dir_training, distfield_dir=heatmap_dir_training)\n",
    "train_loader = DataLoader(VerSe_train, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    # 39 elements (images) in train_loader\n",
    "    # Each element is a tuple of 3 elements: (img, heatmap, msk)\n",
    "    # img: torch.Size([2, 128, 128, 96])\n",
    "\n",
    "input_train, y, z = train_loader.dataset[10]\n",
    "# plt.imshow(input_train[0][64, :, :], cmap='gray')\n",
    "# plt.title('Original')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "## Define model\n",
    "# For simple AE\n",
    "# model = conv_AE([1, 32, 16, 8, 4])\n",
    "model = conv_AE([1, 64, 32, 16, 8])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "\n",
    "o_loss = []\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "recon_img = []\n",
    "recon_img.append(input_train[0][64,:,:].numpy())\n",
    "recon_img_name = []\n",
    "recon_img_name.append('Original')\n",
    "\n",
    "## Train model\n",
    "def train(model, optimizer, epochs, device):\n",
    "    model.train()\n",
    "    step = -1\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        overall_loss = 0\n",
    "\n",
    "        x = input_train[0][64,:,:].unsqueeze(dim=0)\n",
    "        x = x.to(device)\n",
    "\n",
    "        x_reconstructed = model(x)\n",
    "\n",
    "        #-- Loss function\n",
    "        loss = loss_function(x_reconstructed, x)\n",
    "\n",
    "        overall_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss. backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update step\n",
    "        step+=1\n",
    "\n",
    "        # Do evaluation every 50 epoch\n",
    "        if step%25 == 0:\n",
    "            print()\n",
    "            print(\"EVALUATION!\")\n",
    "            model.eval() #Set to evaluation\n",
    "\n",
    "            #Training evaluation\n",
    "            val_loss_eval = []\n",
    "            with torch.no_grad():\n",
    "                inputs = input_train[0][64,:,:].unsqueeze(dim=0)\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                inputs_reconstructed = model(inputs)\n",
    "                \n",
    "                #-- Loss function\n",
    "                v_loss = loss_function(inputs_reconstructed, inputs)\n",
    "\n",
    "                #-- Save image\n",
    "                if step%50 == 0:\n",
    "                    recon_img.append(inputs_reconstructed.detach().cpu().numpy().reshape(128, 96))\n",
    "                    recon_img_name.append('Reconstructed image, '+str(step)+' epochs')\n",
    "\n",
    "\n",
    "                # Save loss\n",
    "                val_loss_eval.append(v_loss.item())\n",
    "            avg_loss_val = np.mean(val_loss_eval)\n",
    "            print(\"Validation loss: \"+str(avg_loss_val))\n",
    "            val_loss.append(avg_loss_val)\n",
    "\n",
    "\n",
    "        o_loss.append(overall_loss)  \n",
    "    \n",
    "\n",
    "train(model, optimizer, num_epochs, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged towards 3.7075730251672215e-05\n"
     ]
    }
   ],
   "source": [
    "## Plotting losses from training\n",
    "\n",
    "print(f\"Converged towards {np.mean(o_loss[350:])}\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(f'Model Loss, batch_size=1, lr={lr}, wd=0.0005')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Avg. loss')\n",
    "ax.set_xticks(np.arange(0, len(o_loss), step= 25))\n",
    "\n",
    "ax.plot(list(range(1, len(o_loss)+1, 1)), o_loss, label='Training loss', color='b')  # Update the plot with the current loss\n",
    "ax.plot(list(range(25, len(o_loss)+1, 25)), val_loss, label='Validation loss', color='r')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting reconstructed images\n",
    "\n",
    "fig, ax  = plt.subplots(2, 3, figsize=(12, 15))\n",
    "ii = [0, 1, 2, 3, 6, 10]\n",
    "\n",
    "for i in range(1,6):\n",
    "    ax[i//3, i%3].imshow(recon_img[ii[i]], cmap='gray')\n",
    "    ax[i//3, i%3].set_title(recon_img_name[ii[i]])\n",
    "\n",
    "\n",
    "ax[0,0].imshow(input_train[0][64, :, :], cmap='gray')\n",
    "ax[0,0].set_title('Original Image')\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second try, Convolutional NN, part 2\n",
    "\n",
    "Training with several images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_AE(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "EVALUATION, EPOCH 0!\n",
      "Validation loss: 0.3024381697177887\n",
      "\n",
      "EVALUATION, EPOCH 25!\n",
      "Validation loss: 0.00010295658285031095\n",
      "\n",
      "EVALUATION, EPOCH 50!\n",
      "Validation loss: 6.172566645545885e-05\n",
      "\n",
      "EVALUATION, EPOCH 75!\n",
      "Validation loss: 6.593994476133958e-05\n",
      "\n",
      "EVALUATION, EPOCH 100!\n",
      "Validation loss: 1.578766205057036e-05\n",
      "\n",
      "EVALUATION, EPOCH 125!\n",
      "Validation loss: 2.385736115684267e-05\n",
      "\n",
      "EVALUATION, EPOCH 150!\n",
      "Validation loss: 9.983570635085925e-05\n",
      "\n",
      "EVALUATION, EPOCH 175!\n",
      "Validation loss: 8.958512808021624e-06\n",
      "\n",
      "EVALUATION, EPOCH 200!\n",
      "Validation loss: 1.9001281543751247e-05\n",
      "\n",
      "EVALUATION, EPOCH 225!\n",
      "Validation loss: 2.1694213501177728e-05\n",
      "\n",
      "EVALUATION, EPOCH 250!\n",
      "Validation loss: 1.0508748346182983e-05\n",
      "\n",
      "EVALUATION, EPOCH 275!\n",
      "Validation loss: 2.0625268007279374e-05\n",
      "\n",
      "EVALUATION, EPOCH 300!\n",
      "Validation loss: 9.367670827487018e-06\n",
      "\n",
      "EVALUATION, EPOCH 325!\n",
      "Validation loss: 7.117343557183631e-06\n",
      "\n",
      "EVALUATION, EPOCH 350!\n",
      "Validation loss: 3.944930995203322e-06\n",
      "\n",
      "EVALUATION, EPOCH 375!\n",
      "Validation loss: 4.43239378000726e-06\n",
      "\n",
      "EVALUATION, EPOCH 400!\n",
      "Validation loss: 2.5435001589357853e-06\n",
      "\n",
      "EVALUATION, EPOCH 425!\n",
      "Validation loss: 7.642166565346997e-06\n",
      "\n",
      "EVALUATION, EPOCH 450!\n",
      "Validation loss: 1.8896434994530864e-05\n",
      "\n",
      "EVALUATION, EPOCH 475!\n",
      "Validation loss: 3.6709391224576393e-06\n"
     ]
    }
   ],
   "source": [
    "#Define paramters\n",
    "parameters_dict = {\n",
    "    'epochs': 500,\n",
    "    'learning_rate': 1e-3, #NOTE - change here\n",
    "    'batch_size': 1, \n",
    "    'weight_decay': 5e-4 \n",
    "}\n",
    "\n",
    "## Unpack parameters\n",
    "num_epochs = parameters_dict['epochs']\n",
    "lr = parameters_dict['learning_rate']\n",
    "batch_size = parameters_dict['batch_size']\n",
    "wd = parameters_dict['weight_decay']\n",
    "\n",
    "\n",
    "## Loading data\n",
    "\n",
    "img_dir_training = \"C:/Users/julie/Bachelor_data/crops_training_prep/img\"\n",
    "heatmap_dir_training = \"C:/Users/julie/Bachelor_data/crops_training_prep/heatmaps\"\n",
    "msk_dir_training = \"C:/Users/julie/Bachelor_data/crops_training_prep/msk\"\n",
    "\n",
    "\n",
    "VerSe_train = LoadData(img_dir=img_dir_training, msk_dir = msk_dir_training, distfield_dir=heatmap_dir_training)\n",
    "train_loader = DataLoader(VerSe_train, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    # 39 elements (images) in train_loader\n",
    "    # Each element is a tuple of 3 elements: (img, heatmap, msk)\n",
    "    # img: torch.Size([2, 128, 128, 96])\n",
    "\n",
    "input_train, y, z = train_loader.dataset[10]\n",
    "# plt.imshow(input_train[0][64, :, :], cmap='gray')\n",
    "# plt.title('Original')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "n = 30\n",
    "dataset = generate_dataset_training(train_loader, n)\n",
    "\n",
    "## Define model\n",
    "# For simple AE\n",
    "model = conv_AE([1, 32, 16, 8, 4])\n",
    "# model = conv_AE([1, 64, 32, 16, 8])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "\n",
    "o_loss = []\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "recon_img = []\n",
    "recon_img.append(dataset[5].numpy())\n",
    "recon_img_name = []\n",
    "recon_img_name.append('Original')\n",
    "\n",
    "## Train model\n",
    "def train(model, optimizer, epochs, device):\n",
    "    model.train()\n",
    "    step = -1\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        overall_loss = 0\n",
    "\n",
    "\n",
    "        for idx, data in enumerate(dataset):\n",
    "            x = data.to(device)\n",
    "            x_reconstructed = model(x)\n",
    "\n",
    "            #-- Loss function\n",
    "            loss = loss_function(x_reconstructed, x)\n",
    "\n",
    "            overall_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss. backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update step\n",
    "            step+=1\n",
    "\n",
    "            # Do evaluation every 50 epoch\n",
    "            if step%750 == 0: #step%250 == 0:\n",
    "                print()\n",
    "                print(f\"EVALUATION, EPOCH {epoch}!\")\n",
    "                model.eval() #Set to evaluation\n",
    "\n",
    "                #Training evaluation\n",
    "                val_loss_eval = []\n",
    "                with torch.no_grad():\n",
    "                    inputs = dataset[5]\n",
    "\n",
    "                    inputs = inputs.to(device)\n",
    "                    inputs_reconstructed = model(inputs)\n",
    "                    \n",
    "                    #-- Loss function\n",
    "                    v_loss = loss_function(inputs_reconstructed, inputs)\n",
    "\n",
    "                    #-- Save image\n",
    "                    if step%1500 == 0: #step%500 == 0: #\n",
    "                        recon_img.append(inputs_reconstructed.detach().cpu().numpy().squeeze())\n",
    "                        recon_img_name.append('Reconstructed image, '+str(step)+' epochs')\n",
    "\n",
    "\n",
    "                    # Save loss\n",
    "                    val_loss_eval.append(v_loss.item())\n",
    "                avg_loss_val = np.mean(val_loss_eval)\n",
    "                print(\"Validation loss: \"+str(avg_loss_val))\n",
    "                val_loss.append(avg_loss_val)\n",
    "\n",
    "\n",
    "        o_loss.append(overall_loss)  \n",
    "    \n",
    "\n",
    "train(model, optimizer, num_epochs, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged towards 0.00040085234829575713\n"
     ]
    }
   ],
   "source": [
    "## Plotting losses from training\n",
    "print(f\"Converged towards {np.mean(o_loss[350:])}\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(f'Model Loss, batch_size=1, lr={lr}, wd=0.0005')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Avg. loss')\n",
    "ax.set_xticks(np.arange(0, len(o_loss), step= 250))\n",
    "\n",
    "ax.plot(list(range(1, len(o_loss)+1, 1)), o_loss, label='Training loss', color='b')  # Update the plot with the current loss\n",
    "ax.plot(list(range(25, len(o_loss)+1, 25)), val_loss, label='Validation loss', color='r')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting reconstructed images\n",
    "\n",
    "fig, ax  = plt.subplots(2, 3, figsize=(12, 15))\n",
    "ii = [0, 1, 2, 3, 6, 10]\n",
    "\n",
    "for i in range(1,6):\n",
    "    ax[i//3, i%3].imshow(recon_img[ii[i]], cmap='gray')\n",
    "    ax[i//3, i%3].set_title(recon_img_name[ii[i]])\n",
    "\n",
    "\n",
    "ax[0,0].imshow(input_train[0][64, :, :], cmap='gray')\n",
    "ax[0,0].set_title('Original Image')\n",
    "\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
