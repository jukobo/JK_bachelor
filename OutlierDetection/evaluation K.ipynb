{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader \n",
    "from itertools import islice\n",
    "\n",
    "\n",
    "from AE_functions import *\n",
    "from eval_functions import *\n",
    "from make_dataset import * \n",
    "\n",
    "# %matplotlib qt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define which training model, that should be evaluated\n",
    "\n",
    "train = '50896'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting the reconstructions\n",
    "\n",
    "no = [0, 0,50, 100, 250, 975] # Change which image, which have to be shown\n",
    "\n",
    "fig, ax  = plt.subplots(2, 3, figsize=(12, 15))\n",
    "\n",
    "for i in range(1,6):\n",
    "    file = f'C:/Users/julie/OneDrive/Skrivebord/Bachelor/JK_bachelor/{train}_training/reconstruction{no[i]}.npy'\n",
    "    x = np.load(file)\n",
    "\n",
    "    x.astype(np.float64)\n",
    "\n",
    "    # Normalize the image, so it fits the float32 format\n",
    "    x = x[0,:,:]\n",
    "    img_float32 = (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "\n",
    "    ax[i//3, i%3].imshow(img_float32, cmap='gray')\n",
    "    ax[i//3, i%3].set_title(f'Reconstructed Image, {no[i]} epochs')\n",
    "\n",
    "\n",
    "file = f'C:/Users/julie/OneDrive/Skrivebord/Bachelor/JK_bachelor/{train}_training/original.npy'\n",
    "x = np.load(file)\n",
    "x.astype(np.float64)\n",
    "x = x[0,:,:]\n",
    "img_float32 = (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "\n",
    "ax[0,0].imshow(img_float32, cmap='gray')\n",
    "ax[0,0].set_title('Original Image')\n",
    "\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig.savefig(f'C:/Users/julie/OneDrive/Skrivebord/merged_{train}.png')  # Save the plot as a PNG file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged towards 0.0007164782436482263\n"
     ]
    }
   ],
   "source": [
    "## Plotting losses from training\n",
    "\n",
    "file_loss = f'C:/Users/julie/OneDrive/Skrivebord/Bachelor/JK_bachelor/{train}_training/o_loss.npy'\n",
    "file_val_loss = f'C:/Users/julie/OneDrive/Skrivebord/Bachelor/JK_bachelor/{train}_training/Val_loss.npy'\n",
    "\n",
    "o_loss = np.load(file_loss)\n",
    "val_loss = np.load(file_val_loss)\n",
    "print(f\"Converged towards {np.mean(o_loss[250:])}\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(f'Model Loss, batch_size=100, lr=0.001, wd=0.0005')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Avg. loss')\n",
    "ax.set_xticks(np.arange(0, len(o_loss), step= 100))\n",
    "# ax.set_xticks(np.arange(0, len(o_loss), step= 200))\n",
    "\n",
    "ax.plot(list(range(1, len(o_loss)+1, 1)), o_loss, label='Training loss', color='b')  # Update the plot with the current loss\n",
    "ax.plot(list(range(25, len(o_loss)+1, 25)), val_loss, label='Validation loss', color='r')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()\n",
    "# fig.savefig(f'C:/Users/julie/OneDrive/Skrivebord/model_loss_{train}.png')  # Save the plot as a PNG file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading test image + outlier image\n",
    "\n",
    "# Loading data (testset, 41 elements)\n",
    "img_dir_test = \"G:/Mit drev/Uni/6. semester/JK_bachelor/Data/Verse20/Outlier_detection/crops_validation_prep/img\"\n",
    "heatmap_dir_test = \"G:/Mit drev/Uni/6. semester/JK_bachelor/Data/Verse20/Outlier_detection/crops_validation_prep/heatmaps\"\n",
    "msk_dir_test = \"G:/Mit drev/Uni/6. semester/JK_bachelor/Data/Verse20/Outlier_detection/crops_validation_prep/msk\"\n",
    "\n",
    "VerSe_test = LoadData(img_dir=img_dir_test, msk_dir = msk_dir_test, distfield_dir=heatmap_dir_test)\n",
    "test_loader = DataLoader(VerSe_test, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "healthy, outlier = healthy_outlier(test_loader)\n",
    "\n",
    "# Create datasets\n",
    "dataset_healthy = generate_dataset(healthy, 120)\n",
    "dataset_outlier = generate_dataset_outlier(outlier, 120, radius=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Evaluating the model with new data (healthy and outliers)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Loading the model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mG:/Mit drev/Uni/6. semester/JK_bachelor/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_training/model_conv_999.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Testing the model\u001b[39;00m\n\u001b[0;32m      9\u001b[0m error_healthy \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mg:\\Mit drev\\Uni\\6. semester\\JK_bachelor\\OutlierDetection\\eval_functions.py:10\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(model_path, dim)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(model_path, dim):\n\u001b[1;32m---> 10\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mconv_AE_UNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(model_path, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     12\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(state_dict)\n",
      "File \u001b[1;32mg:\\Mit drev\\Uni\\6. semester\\JK_bachelor\\OutlierDetection\\AE_functions.py:64\u001b[0m, in \u001b[0;36mconv_AE_UNet.__init__\u001b[1;34m(self, dim, device)\u001b[0m\n\u001b[0;32m     62\u001b[0m hidden_dim_2 \u001b[38;5;241m=\u001b[39m dim[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     63\u001b[0m hidden_dim_3 \u001b[38;5;241m=\u001b[39m dim[\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m---> 64\u001b[0m latent_dim \u001b[38;5;241m=\u001b[39m \u001b[43mdim\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     66\u001b[0m kernel_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m     67\u001b[0m stride \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "## Evaluating the model with new data (healthy and outliers)\n",
    "\n",
    "# Loading the model\n",
    "model_path = f'G:/Mit drev/Uni/6. semester/JK_bachelor/{train}_training/model_conv_999.pth'\n",
    "\n",
    "model = load_model(model_path, [1, 32, 16, 8])\n",
    "\n",
    "# Testing the model\n",
    "error_healthy = []\n",
    "error_outlier = []\n",
    "\n",
    "for i in range(len(dataset_healthy)):\n",
    "    # test_healthy, _, _  = test_loader.dataset[i]\n",
    "    test_healthy = dataset_healthy[i]\n",
    "    loss = evaluate_model(model, test_healthy[0].unsqueeze(dim=0))\n",
    "    error_healthy.append(loss)\n",
    "\n",
    "    # test_outlier, _, _ = test_loader_o.dataset[i]\n",
    "    test_outlier = dataset_outlier[i]\n",
    "    loss = evaluate_model(model, test_outlier[0].unsqueeze(dim=0))\n",
    "    error_outlier.append(loss)\n",
    "\n",
    "\n",
    "hist_values1, hist_values2, bins1, bins2 = plot_histograms(error_healthy, error_outlier, 10)\n",
    "\n",
    "mean_healthy = np.mean(error_healthy)\n",
    "std_healthy = np.std(error_healthy)\n",
    "\n",
    "mean_outlier = np.mean(error_outlier)\n",
    "std_outlier = np.std(error_outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean healthy: 0.01305007900421818, std healthy: 0.012378476236489898\n",
      "Mean outlier: 0.014751443856706221, std outlier: 0.015265706921504101\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean healthy: {mean_healthy}, std healthy: {std_healthy}\")\n",
    "print(f\"Mean outlier: {mean_outlier}, std outlier: {std_outlier}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting the difference from outlier input to reconstructions\n",
    "org_img = dataset_outlier[0].squeeze()\n",
    "reconstructed_img = model(dataset_outlier[0].unsqueeze(dim=0)).squeeze().detach().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 15))\n",
    "\n",
    "ax[0].imshow(dataset_outlier[0].squeeze(), cmap='gray')\n",
    "ax[0].set_title('Original Image')\n",
    "\n",
    "ax[1].imshow(reconstructed_img, cmap='gray')\n",
    "ax[1].set_title('Reconstructed Image')\n",
    "\n",
    "ax[2].imshow(org_img - reconstructed_img, cmap='bwr')\n",
    "ax[2].set_title('Difference')\n",
    "fig.colorbar(ax[2].imshow(org_img - reconstructed_img, cmap='bwr'))\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
