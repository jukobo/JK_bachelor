{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "from AE_functions import *\n",
    "from eval_functions import *\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define which training model, that should be evaluated\n",
    "\n",
    "train = '50176'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting the reconstructions\n",
    "\n",
    "no = 1950 # Change which image, which have to be shown\n",
    "\n",
    "file = f'C:/Users/julie/OneDrive/Skrivebord/Bachelor/JK_bachelor/{train}_training/reconstruction{no}.npy'\n",
    "# file = f'C:/Users/julie/OneDrive/Skrivebord/Bachelor/JK_bachelor/{train}_training/original.npy'\n",
    "\n",
    "x = np.load(file)\n",
    "x.astype(np.float64)\n",
    "\n",
    "# Normalize the image, so it fits the float64 format\n",
    "x = x[0,:,:]\n",
    "img_float32 = (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "\n",
    "plt.imshow(img_float32, cmap='gray')\n",
    "plt.title(f'Reconstructed Image, {no} epochs')\n",
    "# plt.title(f'Original Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged towards 0.00020196787548664057\n"
     ]
    }
   ],
   "source": [
    "## Plotting losses from training\n",
    "\n",
    "file_loss = f'C:/Users/julie/OneDrive/Skrivebord/Bachelor/JK_bachelor/{train}_training/o_loss.npy'\n",
    "file_val_loss = f'C:/Users/julie/OneDrive/Skrivebord/Bachelor/JK_bachelor/{train}_training/Val_loss.npy'\n",
    "\n",
    "o_loss = np.load(file_loss)\n",
    "val_loss = np.load(file_val_loss)\n",
    "print(f\"Converged towards {np.mean(o_loss[500:])}\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(f'Model Loss, batch_size=20, lr=0.001, wd=0.0005')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Avg. loss')\n",
    "ax.set_xticks(np.arange(0, len(o_loss), step= 500))\n",
    "\n",
    "ax.plot(list(range(1, len(o_loss)+1, 1)), o_loss, label='Training loss', color='b')  # Update the plot with the current loss\n",
    "ax.plot(list(range(50, len(o_loss)+1, 50)), val_loss, label='Validation loss', color='r')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()\n",
    "fig.savefig(f'C:/Users/julie/OneDrive/Skrivebord/model_loss_{train}.png')  # Save the plot as a PNG file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading test image + outlier image\n",
    "\n",
    "# Loading healthy data (training set)\n",
    "img_dir_test = \"C:/Users/julie/Bachelor_data/crops_training_prep/img\"\n",
    "heatmap_dir_test = \"C:/Users/julie/Bachelor_data/crops_training_prep/heatmaps\"\n",
    "msk_dir_test = \"C:/Users/julie/Bachelor_data/crops_training_prep/msk\"\n",
    "\n",
    "VerSe_test = LoadData(img_dir=img_dir_test, msk_dir = msk_dir_test, distfield_dir=heatmap_dir_test)\n",
    "test_loader = DataLoader(VerSe_test, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "test_healthy, _, _  = test_loader.dataset[10]\n",
    "plt.imshow(test_healthy[0][64, :, :], cmap='gray')\n",
    "plt.title('Original')\n",
    "plt.show()\n",
    "\n",
    "# Loading outliers (test set)\n",
    "img_dir_test_o = \"C:/Users/julie/Bachelor_data/crops_test_prep/img\"\n",
    "heatmap_dir_test_o = \"C:/Users/julie/Bachelor_data/crops_test_prep/heatmaps\"\n",
    "msk_dir_test_o = \"C:/Users/julie/Bachelor_data/crops_test_prep/msk\"\n",
    "\n",
    "VerSe_test_o = LoadData(img_dir=img_dir_test_o, msk_dir = msk_dir_test_o, distfield_dir=heatmap_dir_test_o)\n",
    "test_loader_o = DataLoader(VerSe_test_o, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "test_outlier, _, _ = test_loader_o.dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluating the model with new data (healthy and outliers)\n",
    "\n",
    "# Loading the model\n",
    "model_path = f'C:/Users/julie/OneDrive/Skrivebord/Bachelor/JK_bachelor/{train}_training/model_conv_1999.pth'\n",
    "\n",
    "model = load_model(model_path, [1, 16, 32, 64, 128])\n",
    "\n",
    "# Testing the model\n",
    "error_healthy = []\n",
    "error_outlier = []\n",
    "\n",
    "for i in range(39):\n",
    "    test_healthy, _, _  = test_loader.dataset[i]\n",
    "    loss = evaluate_model(model, test_healthy[0][64,:,:].unsqueeze(dim=0))\n",
    "    error_healthy.append(loss)\n",
    "\n",
    "    test_outlier, _, _ = test_loader_o.dataset[i]\n",
    "    loss = evaluate_model(model, test_outlier[0][64,:,:].unsqueeze(dim=0))\n",
    "    error_outlier.append(loss)\n",
    "\n",
    "\n",
    "hist_values1, hist_values2, bins1, bins2 = plot_histograms(error_healthy, error_outlier, 15)\n",
    "\n",
    "mean_healthy = np.mean(error_healthy)\n",
    "std_healthy = np.std(error_healthy)\n",
    "\n",
    "mean_outlier = np.mean(error_outlier)\n",
    "std_outlier = np.std(error_outlier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
