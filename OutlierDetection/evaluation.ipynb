{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader \n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from AE_functions import *\n",
    "from eval_functions import *\n",
    "from make_dataset import * \n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define which training model, that should be evaluated\n",
    "\n",
    "train = '54602'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting the reconstructions\n",
    "\n",
    "no = [0, 0, 50, 100, 250, 450] # Change which image, which have to be shown\n",
    "\n",
    "fig, ax  = plt.subplots(2, 3, figsize=(12, 15))\n",
    "\n",
    "for i in range(1,6):\n",
    "    file = f'C:/Users/julie/OneDrive/Skrivebord/Bachelor/JK_bachelor/A_Trainings/{train}_training/reconstruction{no[i]}.npy'\n",
    "    x = np.load(file)\n",
    "\n",
    "    x.astype(np.float64)\n",
    "\n",
    "    # Normalize the image, so it fits the float32 format\n",
    "    x = x[0,:,:]\n",
    "    img_float32 = (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "\n",
    "    ax[i//3, i%3].imshow(img_float32, cmap='gray')\n",
    "    ax[i//3, i%3].set_title(f'Reconstructed Image, {no[i]} epochs')\n",
    "\n",
    "\n",
    "# file = f'C:/Users/julie/OneDrive/Skrivebord/Bachelor/JK_bachelor/{train}_training/original.npy'\n",
    "file = r'C:\\Users\\julie\\OneDrive\\Skrivebord\\Bachelor\\JK_bachelor\\A_Trainings\\54602_training\\original.npy'\n",
    "x = np.load(file)\n",
    "x.astype(np.float64)\n",
    "x = x[0,:,:]\n",
    "img_float32 = (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "\n",
    "ax[0,0].imshow(img_float32, cmap='gray')\n",
    "ax[0,0].set_title('Original Image')\n",
    "\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig.savefig(f'C:/Users/julie/OneDrive/Skrivebord/merged_{train}.png')  # Save the plot as a PNG file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged towards 0.0001958888851384472\n"
     ]
    }
   ],
   "source": [
    "## Plotting losses from training\n",
    "\n",
    "file_loss = f'C:/Users/julie/OneDrive/Skrivebord/Bachelor/JK_bachelor/A_Trainings/{train}_training/o_loss.npy'\n",
    "file_val_loss = f'C:/Users/julie/OneDrive/Skrivebord/Bachelor/JK_bachelor/A_Trainings/{train}_training/Val_loss.npy'\n",
    "\n",
    "o_loss = np.load(file_loss)\n",
    "val_loss = np.load(file_val_loss)\n",
    "print(f\"Converged towards {np.mean(o_loss[250:])}\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(f'Model Loss, batch_size=560, lr=0.001, wd=0.0005')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Avg. loss')\n",
    "# ax.set_xticks(np.arange(0, len(o_loss), step= 100))\n",
    "ax.set_xticks(np.arange(0, len(o_loss), step= 100))\n",
    "\n",
    "ax.plot(list(range(1, len(o_loss)+1, 1)), o_loss, label='Training loss', color='b')  # Update the plot with the current loss\n",
    "# ax.plot(list(range(25, len(o_loss)+1, 25)), val_loss, label='Validation loss', color='r')\n",
    "# ax.plot(list(range(3, len(o_loss)+1, 4)), val_loss[:-62], label='Validation loss', color='r')\n",
    "ax.plot(list(range(25, len(o_loss)+1, 25)), val_loss, label='Validation loss', color='r')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()\n",
    "# fig.savefig(f'C:/Users/julie/OneDrive/Skrivebord/model_loss_{train}.png')  # Save the plot as a PNG file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 24\n"
     ]
    }
   ],
   "source": [
    "## Loading test image + outlier image\n",
    "\n",
    "# Loading data (testset, 41 elements)\n",
    "img_dir_test = \"C:/Users/julie/Bachelor_data/crops_validation_prep/img\"\n",
    "heatmap_dir_test = \"C:/Users/julie/Bachelor_data/crops_validation_prep/heatmaps\"\n",
    "msk_dir_test = \"C:/Users/julie/Bachelor_data/crops_validation_prep/msk\"\n",
    "\n",
    "VerSe_test = LoadData(img_dir=img_dir_test, msk_dir = msk_dir_test, distfield_dir=heatmap_dir_test)\n",
    "test_loader = DataLoader(VerSe_test, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "healthy, outlier = healthy_outlier(test_loader)\n",
    "print(len(healthy), len(outlier))\n",
    "# Create datasets\n",
    "dataset_healthy = generate_dataset(healthy, 120)\n",
    "dataset_outlier = generate_dataset_outlier(outlier, 120, radius=30, mode=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluating the model with new data (healthy and outliers)\n",
    "\n",
    "# Loading the model\n",
    "model_path = f'C:/Users/julie/OneDrive/Skrivebord/Bachelor/JK_bachelor/A_Trainings/{train}_training/model_conv_499.pth'\n",
    "\n",
    "model = load_model(model_path, [1, 8, 16, 32, 64])\n",
    "\n",
    "\n",
    "# Testing the model with MSE\n",
    "error_healthy = []\n",
    "error_outlier = []\n",
    "\n",
    "for i in range(len(dataset_healthy)):\n",
    "    # test_healthy, _, _  = test_loader.dataset[i]\n",
    "    test_healthy = dataset_healthy[i]\n",
    "    loss = evaluate_model(model, test_healthy[0].unsqueeze(dim=0))\n",
    "    error_healthy.append(loss)\n",
    "\n",
    "    # test_outlier, _, _ = test_loader_o.dataset[i]\n",
    "    test_outlier = dataset_outlier[i]\n",
    "    loss = evaluate_model(model, test_outlier[0].unsqueeze(dim=0))\n",
    "    error_outlier.append(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make histogram\n",
    "\n",
    "\n",
    "hist_values1, hist_values2, bins1, bins2 = plot_histograms(error_healthy, error_outlier, 10)\n",
    "\n",
    "mean_healthy = np.mean(error_healthy)\n",
    "std_healthy = np.std(error_healthy)\n",
    "\n",
    "mean_outlier = np.mean(error_outlier)\n",
    "std_outlier = np.std(error_outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean healthy: 0.0002548020523439239, std healthy: 0.00011796082995840363\n",
      "Mean outlier: 0.0005041247325910566, std outlier: 0.0002372936066017816\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean healthy: {mean_healthy}, std healthy: {std_healthy}\")\n",
    "print(f\"Mean outlier: {mean_outlier}, std outlier: {std_outlier}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error over the image is: 0.000249544158577919\n"
     ]
    }
   ],
   "source": [
    "## Plotting the difference from outlier input to reconstructions\n",
    "org_img = dataset_outlier[0].squeeze()\n",
    "reconstructed_img = model(dataset_outlier[0].unsqueeze(dim=0)).squeeze().detach().numpy()\n",
    "\n",
    "mse_img = (org_img - reconstructed_img)**2\n",
    "print(f'The mean squared error over the image is: {torch.mean(mse_img)}')\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "ax[0].imshow(dataset_outlier[0].squeeze(), cmap='gray')\n",
    "ax[0].set_title('Original Image')\n",
    "\n",
    "ax[1].imshow(reconstructed_img, cmap='gray')\n",
    "ax[1].set_title('Reconstructed Image')\n",
    "\n",
    "mse_img = (org_img - reconstructed_img)**2\n",
    "ax[2].imshow(mse_img, cmap='coolwarm')\n",
    "ax[2].set_title('Squared Error Map')\n",
    "fig.colorbar(ax[2].imshow(mse_img, cmap='coolwarm'))\n",
    "\n",
    "# ax[2].imshow(org_img - reconstructed_img, cmap='bwr')\n",
    "# ax[2].set_title('Difference')\n",
    "# fig.colorbar(ax[2].imshow(org_img - reconstructed_img, cmap='bwr'))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluating the model with new data (healthy and outliers)\n",
    "\n",
    "# Testing the model\n",
    "ssim_healthy = []\n",
    "ssim_outlier = []\n",
    "\n",
    "for i in range(len(dataset_healthy)):\n",
    "    # test_healthy, _, _  = test_loader.dataset[i]\n",
    "    test_healthy = dataset_healthy[i]\n",
    "    loss = evaluate_model_SSIM(model, test_healthy[0].unsqueeze(dim=0))\n",
    "    ssim_healthy.append(loss)\n",
    "\n",
    "    # test_outlier, _, _ = test_loader_o.dataset[i]\n",
    "    test_outlier = dataset_outlier[i]\n",
    "    loss = evaluate_model_SSIM(model, test_outlier[0].unsqueeze(dim=0))\n",
    "    ssim_outlier.append(loss)\n",
    "\n",
    "hist_values1, hist_values2, bins1, bins2 = plot_histograms_SSIM(ssim_healthy, ssim_outlier, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean structural similarity index over the image is: 0.979181766043161\n"
     ]
    }
   ],
   "source": [
    "## Plotting the difference from outlier input to reconstructions\n",
    "\n",
    "org_img = dataset_outlier[0].squeeze()\n",
    "org_img_np = org_img.cpu().detach().numpy()\n",
    "\n",
    "reconstructed_img = model(dataset_outlier[0].unsqueeze(dim=0)).squeeze().detach().numpy()\n",
    "reconstructed_img_np = reconstructed_img.astype(np.float64)\n",
    "\n",
    "\n",
    "# Compute SSIM\n",
    "mssim, ssim_map  = ssim(org_img_np, reconstructed_img_np, full=True) # full=True returns the full structural similarity image\n",
    "print('The mean structural similarity index over the image is:',mssim)\n",
    "#plot\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "ax[0].imshow(org_img_np, cmap='gray')\n",
    "ax[0].set_title('Original Image')\n",
    "\n",
    "ax[1].imshow(reconstructed_img_np, cmap='gray')\n",
    "ax[1].set_title('Reconstructed Image')\n",
    "\n",
    "ax[2].imshow(ssim_map, cmap='coolwarm')\n",
    "ax[2].set_title('SSIM Map')\n",
    "fig.colorbar(ax[2].imshow(ssim_map, cmap='coolwarm'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect latent representations for healthy and outlier data\n",
    "latent_representations_healthy = collect_latent_representations(model, dataset_healthy)\n",
    "latent_representations_outlier = collect_latent_representations(model, dataset_outlier)\n",
    "# print(latent_representations_healthy[0].shape)\n",
    "\n",
    "\n",
    "# Flatten the collected latent representations\n",
    "latent_representations_healthy_flat = np.concatenate([latent.flatten().reshape(1, -1) for latent in latent_representations_healthy], axis=0)\n",
    "latent_representations_outlier_flat = np.concatenate([latent.flatten().reshape(1, -1) for latent in latent_representations_outlier], axis=0)\n",
    "\n",
    "merged = np.concatenate((latent_representations_healthy_flat, latent_representations_outlier_flat), axis=0)\n",
    "target = np.zeros((merged.shape[0], 1))\n",
    "target[120:] = 1\n",
    "\n",
    "target2 = []\n",
    "for i in range(merged.shape[0]):\n",
    "    if i < 120:\n",
    "        target2.append('Healthy')\n",
    "    else:\n",
    "        target2.append('Outlier')\n",
    "label_encoder = LabelEncoder()\n",
    "target_encoded = label_encoder.fit_transform(target2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24975745 0.32180864 0.3701342  0.40916827 0.4407394  0.46689463\n",
      " 0.49019325 0.5094184  0.527075   0.5442533  0.5611112  0.57496643\n",
      " 0.588048   0.6007755  0.61282045 0.62415016 0.6349767  0.6449305\n",
      " 0.6546536  0.6635325  0.67199224 0.68028176 0.6879762  0.6954272\n",
      " 0.7025555  0.7093818  0.715914   0.72216296 0.7282692  0.73421055\n",
      " 0.73996806 0.745473   0.75086004 0.7560378  0.7610379  0.7658611\n",
      " 0.77047485 0.77489835 0.7792454  0.78344905 0.78748405 0.79148084\n",
      " 0.7953971  0.79915524 0.8028091  0.8064461  0.8098947  0.8132892\n",
      " 0.8166022  0.8198451  0.82305765 0.8262461  0.82930976 0.8323323\n",
      " 0.83526194 0.8380848  0.84082013 0.8435047  0.84608126 0.8486343\n",
      " 0.85115063 0.8535708  0.8559235  0.8582559  0.860544   0.86278534\n",
      " 0.8650121  0.86717975 0.8692942  0.8713844  0.87345904 0.87543803\n",
      " 0.8773899  0.87932336 0.8811724  0.8829915  0.8847672  0.8865122\n",
      " 0.8882424  0.8899132  0.8915753  0.89320016 0.89480287 0.89635676\n",
      " 0.8978994  0.89942056 0.900906   0.9023861  0.90383965 0.9052771\n",
      " 0.9066986  0.9080899  0.90947545 0.91080755 0.91212916 0.9134364\n",
      " 0.9147257  0.9159994  0.9172669  0.91851526 0.9197369  0.92094797\n",
      " 0.92212987 0.9233011  0.9244614  0.92561567 0.92675996 0.9278793\n",
      " 0.9289827  0.9300782  0.93116784 0.9322365  0.9332976  0.9343426\n",
      " 0.9353738  0.9364005  0.9374101  0.9384027  0.93938476 0.94035125\n",
      " 0.9413073  0.94224733 0.94318324 0.94409263 0.94499004 0.945875\n",
      " 0.94675523 0.94761616 0.948467   0.94930863 0.950137   0.9509606\n",
      " 0.9517697  0.9525728  0.95336103 0.95414335 0.9549173  0.95567906\n",
      " 0.9564365  0.95717984 0.95791644 0.9586449  0.9593611  0.96006346\n",
      " 0.96075773 0.96145093 0.9621338  0.9628074  0.96347785 0.9641437\n",
      " 0.964805   0.9654537  0.9660941  0.9667268  0.9673566  0.96797645\n",
      " 0.96859115 0.9691982  0.9697991  0.97039676 0.97098684 0.9715653\n",
      " 0.9721417  0.97270846 0.9732714  0.9738268  0.9743795  0.974919\n",
      " 0.9754539  0.97598773 0.9765092  0.9770263  0.97753906 0.97804844\n",
      " 0.9785556  0.9790506  0.9795422  0.9800238  0.9804992  0.98097026\n",
      " 0.9814359  0.98189795 0.982352   0.9828047  0.9832484  0.983689\n",
      " 0.98411876 0.98454404 0.98496574 0.9853806  0.9857917  0.9861979\n",
      " 0.9865988  0.9869932  0.9873873  0.9877698  0.98814917 0.9885229\n",
      " 0.98889416 0.9892613  0.9896243  0.98998356 0.9903396  0.9906908\n",
      " 0.99103844 0.99138004 0.9917181  0.9920522  0.992381   0.99270326\n",
      " 0.99302065 0.99333644 0.993652   0.9939576  0.99426174 0.9945567\n",
      " 0.99484885 0.99513626 0.9954201  0.99569935 0.99597394 0.99624205\n",
      " 0.9965076  0.9967634  0.9970152  0.9972587  0.99749744 0.9977335\n",
      " 0.99796796 0.99819666 0.9984228  0.9986458  0.9988571  0.99906504\n",
      " 0.9992674  0.99946576 0.99965036 0.9998314  0.99999994 0.99999994]\n"
     ]
    }
   ],
   "source": [
    "## Explained Variance\n",
    "\n",
    "pca = PCA().fit(merged)\n",
    "print(np.cumsum(pca.explained_variance_ratio_))\n",
    "\n",
    "\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Explained Variance')\n",
    "plt.title('PCA, explained variance')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pca = PCA(n_components=2) \n",
    "# pca.fit(merged)\n",
    "pca.fit(latent_representations_healthy_flat)\n",
    "\n",
    "# Transform\n",
    "latent_pca = pca.transform(merged)\n",
    "\n",
    "\n",
    "## Plotting the PCA visualization\n",
    "color_mapping = {'Healthy': 'blue', 'Outlier': 'red'}\n",
    "colors = [color_mapping[label] for label in target2]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(latent_pca[:, 0], latent_pca[:, 1], c=colors, alpha=0.5) #, cmap='viridis')\n",
    "\n",
    "plt.title('PCA Visualization of Latent Space Representations')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', label='Healthy', markersize=10, markerfacecolor='blue'),\n",
    "                   Line2D([0], [0], marker='o', color='w', label='Outlier', markersize=10, markerfacecolor='red')]\n",
    "plt.legend(handles=legend_elements)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA with 3 components\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(merged)\n",
    "# pca.fit(latent_representations_healthy_flat)\n",
    "\n",
    "#Transform\n",
    "latent_pca = pca.transform(merged)\n",
    "\n",
    "## Plotting the PCA visualization\n",
    "color_mapping = {'Healthy': 'blue', 'Outlier': 'red'}\n",
    "colors = [color_mapping[label] for label in target2]\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(latent_pca[:, 0], latent_pca[:, 1], latent_pca[:, 2], c=colors, alpha=0.5)\n",
    "\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', label='Healthy', markersize=10, markerfacecolor='blue'),\n",
    "                   Line2D([0], [0], marker='o', color='w', label='Outlier', markersize=10, markerfacecolor='red')]\n",
    "plt.legend(handles=legend_elements)\n",
    "\n",
    "ax.set_title('PCA Visualization of Latent Space Representations (3D)')\n",
    "ax.set_xlabel('Principal Component 1')\n",
    "ax.set_ylabel('Principal Component 2')\n",
    "ax.set_zlabel('Principal Component 3')\n",
    "ax.legend(handles=legend_elements)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=42, perplexity=40, init='pca', learning_rate=100, n_iter=10000)\n",
    "\n",
    "# Transform\n",
    "latent_tsne = tsne.fit_transform(merged)\n",
    "\n",
    "## Plotting the t-SNE visualization\n",
    "color_mapping = {'Healthy': 'blue', 'Outlier': 'red'}\n",
    "colors = [color_mapping[label] for label in target2]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(latent_tsne[:, 0], latent_tsne[:, 1], c=colors, alpha=0.5) #, cmap='viridis')\n",
    "\n",
    "plt.title('t-SNE Visualization of Latent Space Representations')\n",
    "plt.xlabel('t-SNE 1')\n",
    "plt.ylabel('t-SNE 2')\n",
    "\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', label='Healthy', markersize=10, markerfacecolor='blue'),\n",
    "                   Line2D([0], [0], marker='o', color='w', label='Outlier', markersize=10, markerfacecolor='red')]\n",
    "plt.legend(handles=legend_elements)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform tsne with 3 components\n",
    "tsne = TSNE(n_components=3, random_state=42, perplexity=30, learning_rate=100) \n",
    "\n",
    "# Transform\n",
    "latent_tsne = tsne.fit_transform(merged)\n",
    "\n",
    "## Plotting the t-SNE visualization\n",
    "color_mapping = {'Healthy': 'blue', 'Outlier': 'red'}\n",
    "colors = [color_mapping[label] for label in target2]\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(latent_tsne[:, 0], latent_tsne[:, 1], latent_tsne[:, 2], c=colors, alpha=0.5)\n",
    "\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', label='Healthy', markersize=10, markerfacecolor='blue'),\n",
    "                   Line2D([0], [0], marker='o', color='w', label='Outlier', markersize=10, markerfacecolor='red')]\n",
    "plt.legend(handles=legend_elements)\n",
    "\n",
    "ax.set_title('TSNE Visualization of Latent Space Representations (3D)')\n",
    "ax.set_xlabel('t-SNE 1')\n",
    "ax.set_ylabel('t-SNE 2')\n",
    "ax.set_zlabel('t-SNE 3')\n",
    "ax.legend(handles=legend_elements)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
